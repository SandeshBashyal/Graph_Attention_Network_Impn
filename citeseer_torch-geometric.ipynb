{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citeseer Dataset Pytorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citeseer()\n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
      "number of graphs:\t\t 1\n",
      "number of classes:\t\t 6\n",
      "number of classes:\t\t [0 1 2 3 4 5]\n",
      "Number of nodes:\t\t 3327\n",
      "number of node features:\t 3703\n",
      "number of edge features:\t 0\n",
      "X shape:  torch.Size([3327, 3703])\n",
      "Edge shape:  torch.Size([2, 9104])\n",
      "Y shape:  torch.Size([3327])\n"
     ]
    }
   ],
   "source": [
    "# Load the Citeseer dataset\n",
    "dataset = Planetoid(root=\"data/Citeseer\", name=\"Citeseer\")\n",
    "data = dataset[0]\n",
    "print(dataset)\n",
    "print(data)\n",
    "print(\"number of graphs:\\t\\t\",len(dataset))\n",
    "print(\"number of classes:\\t\\t\",dataset.num_classes)\n",
    "print(\"number of classes:\\t\\t\",np.unique(data.y))\n",
    "print(f\"Number of nodes:\\t\\t\",data.num_nodes)\n",
    "print(\"number of node features:\\t\",data.num_node_features)\n",
    "print(\"number of edge features:\\t\",data.num_edge_features)\n",
    "print(\"X shape: \", data.x.shape)\n",
    "print(\"Edge shape: \", data.edge_index.shape)\n",
    "print(\"Y shape: \", data.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=8, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.gat1(x, edge_index))\n",
    "        x = F.log_softmax(self.gat2(x, edge_index), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAT(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=8,\n",
    "    out_channels=dataset.num_classes,\n",
    "    heads=8\n",
    ").to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    \n",
    "    train_mask = data.train_mask.bool()\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred[mask] == data.y[mask]).sum()\n",
    "        acc = int(correct) / int(mask.sum())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.8693, Train Acc: 0.6833, Val Acc: 0.3920, Test Acc : 0.3820\n",
      "Epoch 2, Loss: 3.6512, Train Acc: 0.8000, Val Acc: 0.5280, Test Acc : 0.5090\n",
      "Epoch 3, Loss: 3.3702, Train Acc: 0.8667, Val Acc: 0.5520, Test Acc : 0.5420\n",
      "Epoch 4, Loss: 2.9549, Train Acc: 0.8750, Val Acc: 0.5660, Test Acc : 0.5680\n",
      "Epoch 5, Loss: 2.8228, Train Acc: 0.8917, Val Acc: 0.5800, Test Acc : 0.5770\n",
      "Epoch 6, Loss: 2.3719, Train Acc: 0.8833, Val Acc: 0.5680, Test Acc : 0.5710\n",
      "Epoch 7, Loss: 2.0482, Train Acc: 0.9167, Val Acc: 0.5740, Test Acc : 0.5770\n",
      "Epoch 8, Loss: 1.7576, Train Acc: 0.9417, Val Acc: 0.5840, Test Acc : 0.5940\n",
      "Epoch 9, Loss: 1.7642, Train Acc: 0.9500, Val Acc: 0.6060, Test Acc : 0.6060\n",
      "Epoch 10, Loss: 1.4870, Train Acc: 0.9500, Val Acc: 0.6240, Test Acc : 0.6130\n",
      "Epoch 11, Loss: 1.2965, Train Acc: 0.9583, Val Acc: 0.6300, Test Acc : 0.6140\n",
      "Epoch 12, Loss: 1.0744, Train Acc: 0.9583, Val Acc: 0.6500, Test Acc : 0.6220\n",
      "Epoch 13, Loss: 1.1984, Train Acc: 0.9667, Val Acc: 0.6660, Test Acc : 0.6290\n",
      "Epoch 14, Loss: 1.1617, Train Acc: 0.9667, Val Acc: 0.6740, Test Acc : 0.6490\n",
      "Epoch 15, Loss: 1.0124, Train Acc: 0.9583, Val Acc: 0.6760, Test Acc : 0.6560\n",
      "Epoch 16, Loss: 0.9521, Train Acc: 0.9667, Val Acc: 0.6800, Test Acc : 0.6630\n",
      "Epoch 17, Loss: 0.9270, Train Acc: 0.9667, Val Acc: 0.6860, Test Acc : 0.6610\n",
      "Epoch 18, Loss: 1.0825, Train Acc: 0.9667, Val Acc: 0.6720, Test Acc : 0.6600\n",
      "Epoch 19, Loss: 0.8046, Train Acc: 0.9667, Val Acc: 0.6620, Test Acc : 0.6560\n",
      "Epoch 20, Loss: 0.8546, Train Acc: 0.9667, Val Acc: 0.6600, Test Acc : 0.6540\n",
      "Epoch 21, Loss: 0.7549, Train Acc: 0.9833, Val Acc: 0.6500, Test Acc : 0.6530\n",
      "Epoch 22, Loss: 0.7679, Train Acc: 0.9917, Val Acc: 0.6480, Test Acc : 0.6540\n",
      "Epoch 23, Loss: 0.7995, Train Acc: 1.0000, Val Acc: 0.6440, Test Acc : 0.6530\n",
      "Epoch 24, Loss: 0.7877, Train Acc: 1.0000, Val Acc: 0.6460, Test Acc : 0.6600\n",
      "Epoch 25, Loss: 0.7191, Train Acc: 1.0000, Val Acc: 0.6520, Test Acc : 0.6550\n",
      "Epoch 26, Loss: 0.6975, Train Acc: 1.0000, Val Acc: 0.6540, Test Acc : 0.6570\n",
      "Epoch 27, Loss: 0.8498, Train Acc: 1.0000, Val Acc: 0.6540, Test Acc : 0.6650\n",
      "Epoch 28, Loss: 0.7543, Train Acc: 1.0000, Val Acc: 0.6560, Test Acc : 0.6670\n",
      "Epoch 29, Loss: 0.8565, Train Acc: 1.0000, Val Acc: 0.6620, Test Acc : 0.6700\n",
      "Epoch 30, Loss: 0.6271, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6760\n",
      "Epoch 31, Loss: 0.7101, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6730\n",
      "Epoch 32, Loss: 0.8917, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6690\n",
      "Epoch 33, Loss: 0.6309, Train Acc: 1.0000, Val Acc: 0.6880, Test Acc : 0.6700\n",
      "Epoch 34, Loss: 0.7209, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6660\n",
      "Epoch 35, Loss: 0.7667, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6640\n",
      "Epoch 36, Loss: 0.7165, Train Acc: 0.9917, Val Acc: 0.6800, Test Acc : 0.6660\n",
      "Epoch 37, Loss: 0.6778, Train Acc: 0.9917, Val Acc: 0.6780, Test Acc : 0.6640\n",
      "Epoch 38, Loss: 0.4985, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6620\n",
      "Epoch 39, Loss: 0.6663, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6610\n",
      "Epoch 40, Loss: 0.5102, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6610\n",
      "Epoch 41, Loss: 0.6184, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6630\n",
      "Epoch 42, Loss: 0.6577, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6640\n",
      "Epoch 43, Loss: 0.7143, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6670\n",
      "Epoch 44, Loss: 0.7809, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6680\n",
      "Epoch 45, Loss: 0.7463, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6670\n",
      "Epoch 46, Loss: 0.5639, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6640\n",
      "Epoch 47, Loss: 0.6929, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6590\n",
      "Epoch 48, Loss: 0.5573, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6610\n",
      "Epoch 49, Loss: 0.6644, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6570\n",
      "Epoch 50, Loss: 0.5876, Train Acc: 0.9917, Val Acc: 0.6700, Test Acc : 0.6590\n",
      "Epoch 51, Loss: 0.6888, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6650\n",
      "Epoch 52, Loss: 0.7355, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6680\n",
      "Epoch 53, Loss: 0.7023, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6710\n",
      "Epoch 54, Loss: 0.7153, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6750\n",
      "Epoch 55, Loss: 0.5446, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6780\n",
      "Epoch 56, Loss: 0.6391, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6780\n",
      "Epoch 57, Loss: 0.5380, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6770\n",
      "Epoch 58, Loss: 0.6090, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6770\n",
      "Epoch 59, Loss: 0.6426, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6780\n",
      "Epoch 60, Loss: 0.6302, Train Acc: 1.0000, Val Acc: 0.6640, Test Acc : 0.6770\n",
      "Epoch 61, Loss: 0.6523, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6760\n",
      "Epoch 62, Loss: 0.6967, Train Acc: 1.0000, Val Acc: 0.6640, Test Acc : 0.6750\n",
      "Epoch 63, Loss: 0.5417, Train Acc: 1.0000, Val Acc: 0.6640, Test Acc : 0.6720\n",
      "Epoch 64, Loss: 0.5324, Train Acc: 1.0000, Val Acc: 0.6580, Test Acc : 0.6650\n",
      "Epoch 65, Loss: 0.6207, Train Acc: 1.0000, Val Acc: 0.6600, Test Acc : 0.6610\n",
      "Epoch 66, Loss: 0.6839, Train Acc: 1.0000, Val Acc: 0.6560, Test Acc : 0.6600\n",
      "Epoch 67, Loss: 0.5593, Train Acc: 1.0000, Val Acc: 0.6460, Test Acc : 0.6580\n",
      "Epoch 68, Loss: 0.6668, Train Acc: 1.0000, Val Acc: 0.6460, Test Acc : 0.6570\n",
      "Epoch 69, Loss: 0.5497, Train Acc: 1.0000, Val Acc: 0.6460, Test Acc : 0.6520\n",
      "Epoch 70, Loss: 0.5210, Train Acc: 1.0000, Val Acc: 0.6480, Test Acc : 0.6540\n",
      "Epoch 71, Loss: 0.6365, Train Acc: 1.0000, Val Acc: 0.6500, Test Acc : 0.6600\n",
      "Epoch 72, Loss: 0.7868, Train Acc: 1.0000, Val Acc: 0.6500, Test Acc : 0.6620\n",
      "Epoch 73, Loss: 0.6620, Train Acc: 1.0000, Val Acc: 0.6560, Test Acc : 0.6660\n",
      "Epoch 74, Loss: 0.5764, Train Acc: 1.0000, Val Acc: 0.6600, Test Acc : 0.6680\n",
      "Epoch 75, Loss: 0.5652, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6680\n",
      "Epoch 76, Loss: 0.7499, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6680\n",
      "Epoch 77, Loss: 0.6308, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6700\n",
      "Epoch 78, Loss: 0.5502, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6760\n",
      "Epoch 79, Loss: 0.5911, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6740\n",
      "Epoch 80, Loss: 0.5160, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6730\n",
      "Epoch 81, Loss: 0.4237, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6750\n",
      "Epoch 82, Loss: 0.4645, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6760\n",
      "Epoch 83, Loss: 0.6983, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6770\n",
      "Epoch 84, Loss: 0.5738, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6760\n",
      "Epoch 85, Loss: 0.5968, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6710\n",
      "Epoch 86, Loss: 0.7261, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6690\n",
      "Epoch 87, Loss: 0.5427, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6650\n",
      "Epoch 88, Loss: 0.6791, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6630\n",
      "Epoch 89, Loss: 0.4904, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6610\n",
      "Epoch 90, Loss: 0.5922, Train Acc: 1.0000, Val Acc: 0.6620, Test Acc : 0.6620\n",
      "Epoch 91, Loss: 0.6245, Train Acc: 1.0000, Val Acc: 0.6580, Test Acc : 0.6660\n",
      "Epoch 92, Loss: 0.7284, Train Acc: 0.9917, Val Acc: 0.6600, Test Acc : 0.6690\n",
      "Epoch 93, Loss: 0.4978, Train Acc: 0.9917, Val Acc: 0.6580, Test Acc : 0.6690\n",
      "Epoch 94, Loss: 0.7634, Train Acc: 0.9917, Val Acc: 0.6600, Test Acc : 0.6700\n",
      "Epoch 95, Loss: 0.5969, Train Acc: 0.9917, Val Acc: 0.6620, Test Acc : 0.6770\n",
      "Epoch 96, Loss: 0.4691, Train Acc: 0.9917, Val Acc: 0.6620, Test Acc : 0.6760\n",
      "Epoch 97, Loss: 0.5222, Train Acc: 0.9917, Val Acc: 0.6640, Test Acc : 0.6760\n",
      "Epoch 98, Loss: 0.6252, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6820\n",
      "Epoch 99, Loss: 0.6652, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6790\n",
      "Epoch 100, Loss: 0.6250, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6780\n",
      "Epoch 101, Loss: 0.5131, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6790\n",
      "Epoch 102, Loss: 0.5344, Train Acc: 1.0000, Val Acc: 0.6880, Test Acc : 0.6830\n",
      "Epoch 103, Loss: 0.7418, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6750\n",
      "Epoch 104, Loss: 0.5537, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6770\n",
      "Epoch 105, Loss: 0.6896, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6800\n",
      "Epoch 106, Loss: 0.5108, Train Acc: 1.0000, Val Acc: 0.6880, Test Acc : 0.6830\n",
      "Epoch 107, Loss: 0.6022, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6820\n",
      "Epoch 108, Loss: 0.5168, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6800\n",
      "Epoch 109, Loss: 0.6979, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6820\n",
      "Epoch 110, Loss: 0.4271, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6890\n",
      "Epoch 111, Loss: 0.4779, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6800\n",
      "Epoch 112, Loss: 0.5543, Train Acc: 1.0000, Val Acc: 0.6580, Test Acc : 0.6750\n",
      "Epoch 113, Loss: 0.7835, Train Acc: 1.0000, Val Acc: 0.6560, Test Acc : 0.6720\n",
      "Epoch 114, Loss: 0.6105, Train Acc: 1.0000, Val Acc: 0.6560, Test Acc : 0.6680\n",
      "Epoch 115, Loss: 0.6366, Train Acc: 1.0000, Val Acc: 0.6540, Test Acc : 0.6670\n",
      "Epoch 116, Loss: 0.5407, Train Acc: 1.0000, Val Acc: 0.6600, Test Acc : 0.6690\n",
      "Epoch 117, Loss: 0.4481, Train Acc: 1.0000, Val Acc: 0.6640, Test Acc : 0.6650\n",
      "Epoch 118, Loss: 0.5952, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6750\n",
      "Epoch 119, Loss: 0.5886, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6780\n",
      "Epoch 120, Loss: 0.7221, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6830\n",
      "Epoch 121, Loss: 0.5368, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6860\n",
      "Epoch 122, Loss: 0.6988, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6860\n",
      "Epoch 123, Loss: 0.6636, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6920\n",
      "Epoch 124, Loss: 0.5641, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6820\n",
      "Epoch 125, Loss: 0.5187, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6780\n",
      "Epoch 126, Loss: 0.6914, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6770\n",
      "Epoch 127, Loss: 0.5675, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6770\n",
      "Epoch 128, Loss: 0.6966, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6760\n",
      "Epoch 129, Loss: 0.6769, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6770\n",
      "Epoch 130, Loss: 0.5322, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6790\n",
      "Epoch 131, Loss: 0.8844, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6780\n",
      "Epoch 132, Loss: 0.6782, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6760\n",
      "Epoch 133, Loss: 0.4929, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6790\n",
      "Epoch 134, Loss: 0.6214, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6790\n",
      "Epoch 135, Loss: 0.6212, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6830\n",
      "Epoch 136, Loss: 0.5507, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6810\n",
      "Epoch 137, Loss: 0.5848, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6810\n",
      "Epoch 138, Loss: 0.6094, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6790\n",
      "Epoch 139, Loss: 0.6402, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6810\n",
      "Epoch 140, Loss: 0.5543, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6830\n",
      "Epoch 141, Loss: 0.4684, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6860\n",
      "Epoch 142, Loss: 0.5449, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6860\n",
      "Epoch 143, Loss: 0.7202, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6870\n",
      "Epoch 144, Loss: 0.5886, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6860\n",
      "Epoch 145, Loss: 0.5950, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6850\n",
      "Epoch 146, Loss: 0.5883, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6910\n",
      "Epoch 147, Loss: 0.5287, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6850\n",
      "Epoch 148, Loss: 0.5954, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6810\n",
      "Epoch 149, Loss: 0.5624, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6790\n",
      "Epoch 150, Loss: 0.6334, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6730\n",
      "Epoch 151, Loss: 0.7976, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6740\n",
      "Epoch 152, Loss: 0.5875, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6770\n",
      "Epoch 153, Loss: 0.6477, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6750\n",
      "Epoch 154, Loss: 0.7593, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6840\n",
      "Epoch 155, Loss: 0.6081, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6880\n",
      "Epoch 156, Loss: 0.5037, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6920\n",
      "Epoch 157, Loss: 0.3987, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6890\n",
      "Epoch 158, Loss: 0.4939, Train Acc: 0.9917, Val Acc: 0.6920, Test Acc : 0.6900\n",
      "Epoch 159, Loss: 0.6038, Train Acc: 0.9917, Val Acc: 0.6920, Test Acc : 0.6900\n",
      "Epoch 160, Loss: 0.5480, Train Acc: 0.9917, Val Acc: 0.6900, Test Acc : 0.6870\n",
      "Epoch 161, Loss: 0.6421, Train Acc: 0.9917, Val Acc: 0.6860, Test Acc : 0.6880\n",
      "Epoch 162, Loss: 0.5402, Train Acc: 0.9917, Val Acc: 0.6820, Test Acc : 0.6870\n",
      "Epoch 163, Loss: 0.5563, Train Acc: 0.9917, Val Acc: 0.6760, Test Acc : 0.6860\n",
      "Epoch 164, Loss: 0.5038, Train Acc: 0.9917, Val Acc: 0.6760, Test Acc : 0.6830\n",
      "Epoch 165, Loss: 0.5398, Train Acc: 0.9917, Val Acc: 0.6760, Test Acc : 0.6800\n",
      "Epoch 166, Loss: 0.5919, Train Acc: 0.9917, Val Acc: 0.6800, Test Acc : 0.6810\n",
      "Epoch 167, Loss: 0.3465, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6810\n",
      "Epoch 168, Loss: 0.6182, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6790\n",
      "Epoch 169, Loss: 0.4783, Train Acc: 1.0000, Val Acc: 0.6760, Test Acc : 0.6660\n",
      "Epoch 170, Loss: 0.5188, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6620\n",
      "Epoch 171, Loss: 0.4654, Train Acc: 0.9917, Val Acc: 0.6700, Test Acc : 0.6700\n",
      "Epoch 172, Loss: 0.5129, Train Acc: 0.9917, Val Acc: 0.6780, Test Acc : 0.6670\n",
      "Epoch 173, Loss: 0.7442, Train Acc: 0.9917, Val Acc: 0.6780, Test Acc : 0.6770\n",
      "Epoch 174, Loss: 0.6022, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6840\n",
      "Epoch 175, Loss: 0.6503, Train Acc: 1.0000, Val Acc: 0.6900, Test Acc : 0.6930\n",
      "Epoch 176, Loss: 0.5878, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6920\n",
      "Epoch 177, Loss: 0.5951, Train Acc: 1.0000, Val Acc: 0.6880, Test Acc : 0.6880\n",
      "Epoch 178, Loss: 0.5028, Train Acc: 1.0000, Val Acc: 0.6900, Test Acc : 0.6820\n",
      "Epoch 179, Loss: 0.5072, Train Acc: 0.9917, Val Acc: 0.6900, Test Acc : 0.6840\n",
      "Epoch 180, Loss: 0.5591, Train Acc: 0.9917, Val Acc: 0.6840, Test Acc : 0.6810\n",
      "Epoch 181, Loss: 0.6273, Train Acc: 1.0000, Val Acc: 0.6860, Test Acc : 0.6790\n",
      "Epoch 182, Loss: 0.5392, Train Acc: 1.0000, Val Acc: 0.6820, Test Acc : 0.6740\n",
      "Epoch 183, Loss: 0.5207, Train Acc: 1.0000, Val Acc: 0.6840, Test Acc : 0.6680\n",
      "Epoch 184, Loss: 0.6636, Train Acc: 1.0000, Val Acc: 0.6800, Test Acc : 0.6680\n",
      "Epoch 185, Loss: 0.5748, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6660\n",
      "Epoch 186, Loss: 0.7383, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6670\n",
      "Epoch 187, Loss: 0.5322, Train Acc: 1.0000, Val Acc: 0.6740, Test Acc : 0.6650\n",
      "Epoch 188, Loss: 0.4953, Train Acc: 1.0000, Val Acc: 0.6780, Test Acc : 0.6600\n",
      "Epoch 189, Loss: 0.4478, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6560\n",
      "Epoch 190, Loss: 0.5686, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6550\n",
      "Epoch 191, Loss: 0.5208, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6610\n",
      "Epoch 192, Loss: 0.4972, Train Acc: 1.0000, Val Acc: 0.6720, Test Acc : 0.6680\n",
      "Epoch 193, Loss: 0.5128, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6700\n",
      "Epoch 194, Loss: 0.3958, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6760\n",
      "Epoch 195, Loss: 0.5832, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6810\n",
      "Epoch 196, Loss: 0.4387, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6860\n",
      "Epoch 197, Loss: 0.4779, Train Acc: 1.0000, Val Acc: 0.6680, Test Acc : 0.6910\n",
      "Epoch 198, Loss: 0.4011, Train Acc: 1.0000, Val Acc: 0.6700, Test Acc : 0.6870\n",
      "Epoch 199, Loss: 0.5139, Train Acc: 1.0000, Val Acc: 0.6640, Test Acc : 0.6900\n",
      "Epoch 200, Loss: 0.4282, Train Acc: 1.0000, Val Acc: 0.6660, Test Acc : 0.6920\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    loss = train(model, data, optimizer, criterion)\n",
    "    train_acc = test(model, data, data.train_mask.bool())\n",
    "    val_acc = test(model, data, data.val_mask.bool())\n",
    "    test_acc = test(model, data, data.test_mask.bool())\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc : {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
